{
  "hash": "cfbcb36c264251de6d85d768638a68e1",
  "result": {
    "markdown": "---\ntitle: \"Transit Cost Analysis\"\nsubtitle: \"Tidy Tuesday, 2021-01-05\"\nauthor: \"Juha Päällysaho\"\ndate: \"2021-04-01\"\ndate-modified: \"2023-11-23\"\nexecute:\n  echo: true\n  warning: false\ndraft: true\nformat: html\n---\n\n\nload libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(colorspace)\n```\n:::\n\n\n# get the data\n\nload the data from tidytuesdayR package\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuesdata <- tidytuesdayR::tt_load(\"2021-01-05\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tDownloading file 1 of 1: `transit_cost.csv`\n```\n:::\n\n```{.r .cell-code}\nraw <- tuesdata |>\n  pluck(1) |>\n  type_convert()\n```\n:::\n\n\n# focus\n\n- what explains the transit costs in different continents?\n    - how many year the line took to build (end_year - start_year)\n    - length\n    - stations\n    - tunnel or ratio of tunnels from total length\n    - cost = real_cost / length\n  - add continent factor since its mentioned in the Tuesday docs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw |> skimr::skim()\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |raw  |\n|Number of rows           |544  |\n|Number of columns        |20   |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |11   |\n|numeric                  |9    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|country       |         7|          0.99|   2|   2|     0|       56|          0|\n|city          |         7|          0.99|   4|  16|     0|      140|          0|\n|line          |         7|          0.99|   2|  46|     0|      366|          0|\n|start_year    |        53|          0.90|   4|   9|     0|       40|          0|\n|end_year      |        71|          0.87|   1|   4|     0|       36|          0|\n|tunnel_per    |        32|          0.94|   5|   7|     0|      134|          0|\n|source1       |        12|          0.98|   4|  54|     0|       17|          0|\n|currency      |         7|          0.99|   2|   3|     0|       39|          0|\n|real_cost     |         0|          1.00|   1|  10|     0|      534|          0|\n|source2       |        10|          0.98|   3|  16|     0|       12|          0|\n|reference     |        19|          0.97|   3| 302|     0|      350|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable    | n_missing| complete_rate|      mean|         sd|      p0|     p25|      p50|      p75|        p100|hist  |\n|:----------------|---------:|-------------:|---------:|----------:|-------:|-------:|--------:|--------:|-----------:|:-----|\n|e                |         7|          0.99|   7738.76|     463.23| 7136.00| 7403.00|  7705.00|  7977.00|     9510.00|▇▇▂▁▁ |\n|rr               |         8|          0.99|      0.06|       0.24|    0.00|    0.00|     0.00|     0.00|        1.00|▇▁▁▁▁ |\n|length           |         5|          0.99|     58.34|     621.20|    0.60|    6.50|    15.77|    29.08|    12256.98|▇▁▁▁▁ |\n|tunnel           |        32|          0.94|     29.38|     344.04|    0.00|    3.40|     8.91|    21.52|     7790.78|▇▁▁▁▁ |\n|stations         |        15|          0.97|     13.81|      13.70|    0.00|    4.00|    10.00|    20.00|      128.00|▇▁▁▁▁ |\n|cost             |         7|          0.99| 805438.12| 6708033.07|    0.00| 2289.00| 11000.00| 27000.00| 90000000.00|▇▁▁▁▁ |\n|year             |         7|          0.99|   2014.91|       5.64| 1987.00| 2012.00|  2016.00|  2019.00|     2027.00|▁▁▂▇▂ |\n|ppp_rate         |         9|          0.98|      0.66|       0.87|    0.00|    0.24|     0.26|     1.00|        5.00|▇▂▁▁▁ |\n|cost_km_millions |         2|          1.00|    232.98|     257.22|    7.79|  134.86|   181.25|   241.43|     3928.57|▇▁▁▁▁ |\n:::\n:::\n\n\n\ncheck quality of real_cost, start and end year column since its read as character\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw |>\n  filter(if_any(c(real_cost, start_year, end_year), \\(x) str_detect(x, \"[[:alpha:]]\", negate = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 537 × 20\n       e country city   line  start_year end_year    rr length tunnel_per tunnel\n   <dbl> <chr>   <chr>  <chr> <chr>      <chr>    <dbl>  <dbl> <chr>       <dbl>\n 1  7136 CA      Vanco… Broa… 2020       2025         0    5.7 87.72%        5  \n 2  7137 CA      Toron… Vaug… 2009       2017         0    8.6 100.00%       8.6\n 3  7138 CA      Toron… Scar… 2020       2030         0    7.8 100.00%       7.8\n 4  7139 CA      Toron… Onta… 2020       2030         0   15.5 57.00%        8.8\n 5  7144 CA      Toron… Yong… 2020       2030         0    7.4 100.00%       7.4\n 6  7145 NL      Amste… Nort… 2003       2018         0    9.7 73.00%        7.1\n 7  7146 CA      Montr… Blue… 2020       2026         0    5.8 100.00%       5.8\n 8  7147 US      Seatt… U-Li… 2009       2016         0    5.1 100.00%       5.1\n 9  7152 US      Los A… Purp… 2020       2027         0    4.2 100.00%       4.2\n10  7153 US      Los A… Purp… 2018       2026         0    4.2 100.00%       4.2\n# ℹ 527 more rows\n# ℹ 10 more variables: stations <dbl>, source1 <chr>, cost <dbl>,\n#   currency <chr>, year <dbl>, ppp_rate <dbl>, real_cost <chr>,\n#   cost_km_millions <dbl>, source2 <chr>, reference <chr>\n```\n:::\n:::\n\n\n# eda\n\nremove rows with missing or malformed values and convert to numeric. \nprepare features for analysis and modeling\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost <- raw %>%\n  filter(!if_any(c(start_year, end_year, real_cost), \\(x) str_detect(x, \"[[:alpha:]]\")), real_cost != \"0\") |>\n  type_convert() |>\n  transmute(\n    build_cost = real_cost / length,\n    building_time_years = end_year - start_year,\n    rail_lenght = length,\n    how_many_stations = stations,\n    tunnel_ratio = tunnel / rail_lenght,\n    country = str_replace(country, \"UK\", \"GB\"),\n    continent = countrycode::countrycode(country, \"iso2c\", \"continent\")\n  )\n\ntransit_cost\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 460 × 7\n   build_cost building_time_years rail_lenght how_many_stations tunnel_ratio\n        <dbl>               <dbl>       <dbl>             <dbl>        <dbl>\n 1       417.                   5         5.7                 6        0.877\n 2       301.                   8         8.6                 6        1    \n 3       592.                  10         7.8                 3        1    \n 4       465.                  10        15.5                15        0.568\n 5       636.                  10         7.4                 6        1    \n 6       415.                  15         9.7                 8        0.732\n 7       652.                   6         5.8                 5        1    \n 8       344.                   7         5.1                 2        1    \n 9       857.                   7         4.2                 2        1    \n10       571.                   8         4.2                 2        1    \n# ℹ 450 more rows\n# ℹ 2 more variables: country <chr>, continent <chr>\n```\n:::\n:::\n\n\nre-evaluate the data quality after transformation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |> skimr::skim()\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |             |\n|:------------------------|:------------|\n|Name                     |transit_cost |\n|Number of rows           |460          |\n|Number of columns        |7            |\n|_______________________  |             |\n|Column type frequency:   |             |\n|character                |2            |\n|numeric                  |5            |\n|________________________ |             |\n|Group variables          |None         |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|country       |         0|             1|   2|   2|     0|       56|          0|\n|continent     |         0|             1|   4|   8|     0|        5|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable       | n_missing| complete_rate|   mean|     sd|   p0|    p25|    p50|    p75|    p100|hist  |\n|:-------------------|---------:|-------------:|------:|------:|----:|------:|------:|------:|-------:|:-----|\n|build_cost          |         0|          1.00| 236.05| 273.82| 7.79| 134.68| 181.92| 239.62| 3928.57|▇▁▁▁▁ |\n|building_time_years |         0|          1.00|   5.82|   3.08| 1.00|   4.00|   5.00|   7.00|   24.00|▇▅▁▁▁ |\n|rail_lenght         |         0|          1.00|  21.00|  22.20| 0.60|   6.12|  15.40|  28.35|  200.00|▇▁▁▁▁ |\n|how_many_stations   |         4|          0.99|  13.82|  13.92| 0.00|   4.00|  10.00|  20.00|  128.00|▇▁▁▁▁ |\n|tunnel_ratio        |        20|          0.96|   0.74|   0.37| 0.00|   0.50|   1.00|   1.00|    1.00|▂▁▁▁▇ |\n:::\n:::\n\n\n\n\n## how continents look like ?\n\nafrica, oceania and south america have very few datapoints, which can cause problems with modeling\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |>\n  count(continent) |>\n  mutate(ratio = scales::percent(n / sum(n)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 3\n  continent     n ratio \n  <chr>     <int> <chr> \n1 Africa        3 0.65% \n2 Americas     36 7.83% \n3 Asia        316 68.70%\n4 Europe      100 21.74%\n5 Oceania       5 1.09% \n```\n:::\n:::\n\nhowever the data from africa, oceania and south america is not very different from other continents, so i will keep them in the analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |>\n    mutate(building_cost_log = log10(build_cost), .before = 1) |>\n  group_by(continent) |>\n  summarise(across(where(is.double), list(mean = mean, median = median)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 13\n  continent building_cost_log_mean building_cost_log_median build_cost_mean\n  <chr>                      <dbl>                    <dbl>           <dbl>\n1 Africa                      2.41                     2.64            398.\n2 Americas                    2.59                     2.50            618.\n3 Asia                        2.25                     2.26            201.\n4 Europe                      2.21                     2.20            193.\n5 Oceania                     2.55                     2.55            471.\n# ℹ 9 more variables: build_cost_median <dbl>, building_time_years_mean <dbl>,\n#   building_time_years_median <dbl>, rail_lenght_mean <dbl>,\n#   rail_lenght_median <dbl>, how_many_stations_mean <dbl>,\n#   how_many_stations_median <dbl>, tunnel_ratio_mean <dbl>,\n#   tunnel_ratio_median <dbl>\n```\n:::\n:::\n\n\n\nbuilding time per continent, the data is skewed to the right, which means that most of the lines were built in less than 10 years\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |>\n  ggplot(aes(building_time_years, fill = continent)) +\n  geom_histogram(binwidth = 0.8) +\n  labs(\n    title = \"building time per continent\",\n    subtitle = \"binwidth = 0.8\"\n  )\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nthis represent the building time better, asia seems to build the lines faster than other continents. however if track lenght is taken into account, the picture changes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb_size <- 1.7\ntransit_cost |>\n  ggplot(aes(building_time_years)) +\n  geom_freqpoly(aes(color = continent), binwidth = b_size) +\n  labs(\n    title = \"building time per continent\",\n    subtitle = str_glue(\"binwidth = {b_size}\")\n  )\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntransit_cost |>\n  ggplot(aes(building_time_years)) +\n  geom_histogram(aes(fill = continent), position = \"fill\", binwidth = b_size) +\n  labs(\n    title = \"portion of building time per continent\",\n    subtitle = str_glue(\"binwidth = {b_size}\")\n  )\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n\n## building time vs track lenght\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# scatter plot with building time and track lenght\ntransit_cost |>\n  ggplot(aes(building_time_years, rail_lenght, color = continent)) +\n  geom_jitter(alpha = 1 / 2) +\n  geom_smooth(method = \"lm\", se = F) +\n  labs(title = \"building time vs track lenght\",\n       subtitle = \"y scale is per continent\") +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete_sequential(palette = \"Heat\") +\n  facet_wrap(vars(continent), scales = \"free_y\")\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n## correlation\n\n### complete dataset\n\ntunnel ratio and building time have statistically significant correlation to build cost.\ncorrelation against build cost is not very strong, but it is statistically significant.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(correlation)\ntransit_cost |>\n  correlation() |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Correlation Matrix (pearson-method)\n\nParameter           | tunnel_ratio | how_many_stations | rail_lenght | building_time_years\n------------------------------------------------------------------------------------------\nbuild_cost          |       0.16** |             -0.10 |       -0.10 |             0.24***\nbuilding_time_years |        -0.03 |             0.13* |        0.10 |                    \nrail_lenght         |     -0.21*** |           0.85*** |             |                    \nhow_many_stations   |     -0.24*** |                   |             |                    \n\np-value adjustment method: Holm (1979)\n```\n:::\n:::\n\n\n\n### per continent\n\ncorrelation in continents is not strong.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |>\n  group_by(continent) |>\n  correlation() |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Correlation Matrix (pearson-method)\n\nGroup    |           Parameter | tunnel_ratio | how_many_stations | rail_lenght | building_time_years\n-----------------------------------------------------------------------------------------------------\nAfrica   |          build_cost |         0.95 |             -0.99 |       -1.00 |                0.25\nAfrica   | building_time_years |        -0.05 |             -0.13 |       -0.19 |                    \nAfrica   |         rail_lenght |        -0.97 |              1.00 |             |                    \nAfrica   |   how_many_stations |        -0.98 |                   |             |                    \nAmericas |          build_cost |         0.32 |            -0.45* |      -0.48* |                0.40\nAmericas | building_time_years |         0.09 |             -0.02 |       -0.07 |                    \nAmericas |         rail_lenght |        -0.42 |           0.90*** |             |                    \nAmericas |   how_many_stations |        -0.39 |                   |             |                    \nAsia     |          build_cost |       0.19** |              0.03 |    9.58e-03 |               0.15*\nAsia     | building_time_years |       -0.17* |           0.22*** |      0.21** |                    \nAsia     |         rail_lenght |        -0.13 |           0.85*** |             |                    \nAsia     |   how_many_stations |       -0.18* |                   |             |                    \nEurope   |          build_cost |         0.24 |             -0.04 |    1.67e-03 |                0.23\nEurope   | building_time_years |         0.10 |            0.36** |        0.22 |                    \nEurope   |         rail_lenght |        -0.14 |           0.87*** |             |                    \nEurope   |   how_many_stations |        -0.09 |                   |             |                    \nOceania  |          build_cost |         0.58 |             -0.45 |       -0.63 |                0.77\nOceania  | building_time_years |         0.30 |             -0.26 |       -0.42 |                    \nOceania  |         rail_lenght |       -0.99* |              0.89 |             |                    \nOceania  |   how_many_stations |        -0.88 |                   |             |                    \n\np-value adjustment method: Holm (1979)\n```\n:::\n:::\n\n\n# modeling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n```\n:::\n\n\nsplit data to training and testing, i dont use validation set since the data size is small\ntesting set purpose is to confirm that the build model has potential to work with new data.\ni use log10 of build cost to make the data more normal distributed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\ntransit_cost_log <- transit_cost |>\n  mutate(build_cost = log10(build_cost))\n\nsplit <- initial_split(transit_cost_log, prop = 0.8)\ntrn <- training(split)\ntst <- testing(split)\n```\n:::\n\n\n## recipe\n\nbuilding tune and tunnel ratio seemed to have correlation with building cost. \nsome of the tunnel ratios were missing, i use mean imputation to insert replacement data.\ni also add recipe with all features to see if it improves the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_rec <- recipe(build_cost ~ building_time_years + tunnel_ratio, data = trn) %>%\n  step_impute_mean(tunnel_ratio) |>\n  prep()\n```\n:::\n\n\n## cross validation\n\nI am using standard 10 fold cross validation to test the models later.\ncross validation is used to estimate how well the model will perform in practice without using the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_folds <- vfold_cv(trn, v = 10)\ntransit_folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits           id    \n   <list>           <chr> \n 1 <split [331/37]> Fold01\n 2 <split [331/37]> Fold02\n 3 <split [331/37]> Fold03\n 4 <split [331/37]> Fold04\n 5 <split [331/37]> Fold05\n 6 <split [331/37]> Fold06\n 7 <split [331/37]> Fold07\n 8 <split [331/37]> Fold08\n 9 <split [332/36]> Fold09\n10 <split [332/36]> Fold10\n```\n:::\n:::\n\n\n\n## select models\n\nlow bias (blackbox) models can learn the relationship so well that it memorizes the training set, which means that when model is used with test data, the performance can degrade. \nlinear regression is the most simple model, but it can be used as a baseline to compare other models.\nrandom forest and xgboost are blackbox models, which can learn complex relationships, but they are prone to overfitting. cross validation can help to reduce overfitting.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels <- list(lin = linear_reg(), rand = rand_forest(mode = \"regression\"), xg = boost_tree(mode = \"regression\"))\nmodelset <- workflow_set(list(transit_rec), models)\nkeep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\nmetrics_list <- metric_set(rmse, rsq, mae)\n```\n:::\n\n\n### fit models\n\nworkflowmap has all the models and recipes in a list and it fits all the models to the training set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_models <- function(.data) {\n  .data |>\n    workflow_map(\"fit_resamples\",\n      seed = 10101, verbose = T,\n      resamples = transit_folds, control = keep_pred,\n      metrics = metrics_list\n    )\n}\n\nres <- modelset |> fit_models()\n\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 3 × 4\n  wflow_id    info             option    result   \n  <chr>       <list>           <list>    <list>   \n1 recipe_lin  <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n2 recipe_rand <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n3 recipe_xg   <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n```\n:::\n:::\n\n\n### evaluate models\n\nrmse is used to evaluate the models, since it is easy to interpret and it is in the same units as the target variable. based on ranking, linear regression is the best model based on rmse. however the difference between the models is not very big.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres |> collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 9\n  wflow_id    .config      preproc model .metric .estimator   mean     n std_err\n  <chr>       <chr>        <chr>   <chr> <chr>   <chr>       <dbl> <int>   <dbl>\n1 recipe_lin  Preprocesso… recipe  line… mae     standard   0.187     10  0.0111\n2 recipe_lin  Preprocesso… recipe  line… rmse    standard   0.265     10  0.0188\n3 recipe_lin  Preprocesso… recipe  line… rsq     standard   0.142     10  0.0412\n4 recipe_rand Preprocesso… recipe  rand… mae     standard   0.196     10  0.0100\n5 recipe_rand Preprocesso… recipe  rand… rmse    standard   0.272     10  0.0156\n6 recipe_rand Preprocesso… recipe  rand… rsq     standard   0.102     10  0.0258\n7 recipe_xg   Preprocesso… recipe  boos… mae     standard   0.205     10  0.0118\n8 recipe_xg   Preprocesso… recipe  boos… rmse    standard   0.285     10  0.0176\n9 recipe_xg   Preprocesso… recipe  boos… rsq     standard   0.0839    10  0.0172\n```\n:::\n\n```{.r .cell-code}\nres |> autoplot()\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nres |> rank_results(rank_metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 9\n  wflow_id    .config      .metric   mean std_err     n preprocessor model  rank\n  <chr>       <chr>        <chr>    <dbl>   <dbl> <int> <chr>        <chr> <int>\n1 recipe_lin  Preprocesso… mae     0.187   0.0111    10 recipe       line…     1\n2 recipe_lin  Preprocesso… rmse    0.265   0.0188    10 recipe       line…     1\n3 recipe_lin  Preprocesso… rsq     0.142   0.0412    10 recipe       line…     1\n4 recipe_rand Preprocesso… mae     0.196   0.0100    10 recipe       rand…     2\n5 recipe_rand Preprocesso… rmse    0.272   0.0156    10 recipe       rand…     2\n6 recipe_rand Preprocesso… rsq     0.102   0.0258    10 recipe       rand…     2\n7 recipe_xg   Preprocesso… mae     0.205   0.0118    10 recipe       boos…     3\n8 recipe_xg   Preprocesso… rmse    0.285   0.0176    10 recipe       boos…     3\n9 recipe_xg   Preprocesso… rsq     0.0839  0.0172    10 recipe       boos…     3\n```\n:::\n:::\n\n\n\n## tune hyperparameters\n\nlets tune the hyperparameters of random forest and xgboost models to see if we can improve the performance. I will keep the linear regression model as a baseline.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxg_tune <- boost_tree(\n  mode = \"regression\",\n  trees = 1000,\n  min_n = tune(),\n  tree_depth = tune(),\n  learn_rate = tune()\n)\nxg_tune\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  trees = 1000\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n\nComputational engine: xgboost \n```\n:::\n\n```{.r .cell-code}\nrf_tune <- rand_forest(\n  mode = \"regression\",\n  mtry = tune(),\n  trees = 1000,\n  min_n = tune()\n)\n\nmodelset2 <- workflow_set(list(pari = transit_rec), list(reg = linear_reg(),rf_tune = rf_tune, xg_tune = xg_tune), cross = TRUE)\nmodelset2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 3 × 4\n  wflow_id     info             option    result    \n  <chr>        <list>           <list>    <list>    \n1 pari_reg     <tibble [1 × 4]> <opts[0]> <list [0]>\n2 pari_rf_tune <tibble [1 × 4]> <opts[0]> <list [0]>\n3 pari_xg_tune <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nres2 <- modelset2 |> workflow_map(\n  resamples = transit_folds, grid = 10, verbose = TRUE, seed = 10102,\n  control = keep_pred,\n  metrics = metrics_list\n)\n\nres2 |> collect_metrics() |>\n    arrange(-mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 63 × 9\n   wflow_id     .config     preproc model .metric .estimator  mean     n std_err\n   <chr>        <chr>       <chr>   <chr> <chr>   <chr>      <dbl> <int>   <dbl>\n 1 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.576    10  0.0206\n 2 pari_xg_tune Preprocess… recipe  boos… mae     standard   0.523    10  0.0195\n 3 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.308    10  0.0171\n 4 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.298    10  0.0168\n 5 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.295    10  0.0160\n 6 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.287    10  0.0165\n 7 pari_xg_tune Preprocess… recipe  boos… rmse    standard   0.286    10  0.0162\n 8 pari_rf_tune Preprocess… recipe  rand… rmse    standard   0.284    10  0.0153\n 9 pari_rf_tune Preprocess… recipe  rand… rmse    standard   0.283    10  0.0153\n10 pari_rf_tune Preprocess… recipe  rand… rmse    standard   0.279    10  0.0150\n# ℹ 53 more rows\n```\n:::\n:::\n\n\n## analyse models\n\ngenerally there is little diffence between the models, this is due to dataset being simple (small amount of features and datapoints), whic means simple liner regression can learn the relationship well. Below its clear that  non tuned models are quite simeilar to tuned models.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n res |> autoplot() / res2 |> autoplot() + plot_annotation(title = \"Non Tuned (top row) vs Tuned models (bottom row)\")\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n## select model\n\nselect best model based on rmse metric and fit to the whole training set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbestmodel <- res2 |>\n  extract_workflow_set_result(\"pari_xg_tune\") |>\n  select_best(metric = \"rmse\")\nbestmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  min_n tree_depth learn_rate .config              \n  <int>      <int>      <dbl> <chr>                \n1    33          1     0.0539 Preprocessor1_Model08\n```\n:::\n\n```{.r .cell-code}\nresult <- res2 |>\n  extract_workflow(\"pari_xg_tune\") |>\n  finalize_workflow(bestmodel) |>\n  last_fit(split = split)\n```\n:::\n\n\nthe modeling is done, but out of curiosity lets if there is a difference between training metrics and test metrics.\nrmse is slightly higher in test set, but the difference is not big, which means that the model is not overfitting.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult |>\n  collect_predictions() |>\n  metrics(truth = build_cost, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      0.227 \n2 rsq     standard      0.0733\n3 mae     standard      0.178 \n```\n:::\n\n```{.r .cell-code}\nrank_results(res2, rank_metric = \"rmse\", select_best = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 9\n  wflow_id     .config      .metric  mean std_err     n preprocessor model  rank\n  <chr>        <chr>        <chr>   <dbl>   <dbl> <int> <chr>        <chr> <int>\n1 pari_xg_tune Preprocesso… mae     0.187 0.00972    10 recipe       boos…     1\n2 pari_xg_tune Preprocesso… rmse    0.262 0.0160     10 recipe       boos…     1\n3 pari_xg_tune Preprocesso… rsq     0.153 0.0382     10 recipe       boos…     1\n4 pari_reg     Preprocesso… mae     0.187 0.0111     10 recipe       line…     2\n5 pari_reg     Preprocesso… rmse    0.265 0.0188     10 recipe       line…     2\n6 pari_reg     Preprocesso… rsq     0.142 0.0412     10 recipe       line…     2\n7 pari_rf_tune Preprocesso… mae     0.189 0.00993    10 recipe       rand…     3\n8 pari_rf_tune Preprocesso… rmse    0.266 0.0160     10 recipe       rand…     3\n9 pari_rf_tune Preprocesso… rsq     0.130 0.0350     10 recipe       rand…     3\n```\n:::\n:::\n\n\n## check predicions vs actual values\n\nPlot the predictions vs actual values. I convert the values back to original scale to make the plot more readable for human. Generally the predictions are close to actual values, but there are some outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult |>\n  collect_predictions() |>\n    mutate(build_cost = 10 ^ build_cost,\n           .pred = 10^.pred) |>\n  ggplot(aes(.pred, build_cost)) +\n  geom_point(alpha = 0.5) +\n  geom_abline() +\n  coord_obs_pred() +\n  labs(title = \"Predicted vs actual value\") +\n  labs(x = \"Predicted\", y = \"Actual\")\n```\n\n::: {.cell-output-display}\n![](transit_cost_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntransit_cost |> \n    summarise(build_cost = mean(build_cost), #add other statistical metrics\n              sd = sd(build_cost),\n              median = median(build_cost),\n              min = min(build_cost),\n              max = max(build_cost),\n              n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  build_cost    sd median   min   max     n\n       <dbl> <dbl>  <dbl> <dbl> <dbl> <int>\n1       236.    NA   236.  236.  236.   460\n```\n:::\n:::\n",
    "supporting": [
      "transit_cost_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}