---
title: "Transit Cost Analysis"
subtitle: "Tidy Tuesday, 2021-01-05"
author: "Juha Päällysaho"
date: "2021-04-01"
date-modified: "2023-11-23"
execute:
  echo: true
  warning: false
draft: true
format: html
---

```{r}
library(tidyverse)
```

# get the data

```{r}
tuesdata <- tidytuesdayR::tt_load("2021-01-05")

raw <- tuesdata |>
  pluck(1) |>
  type_convert()
```

# focus

- what explains the transit costs?
  - select variables/features
    - end_year - start_year
    - length
    - stations
    - tunnel
    - cost = real_cost / length
  - add continent factor since its mentioned in the Tuesday docs

```{r}
raw |> skim()
```


check quality of real_cost, start and end year column since its read as character

```{r}
raw |>
  filter(if_any(c(real_cost, start_year, end_year), \(x) str_detect(x, "[[:alpha:]]", negate = TRUE)))
```

# eda

```{r}
transit_cost <- raw %>%
  filter(!if_any(c(start_year, end_year, real_cost), \(x) str_detect(x, "[[:alpha:]]")), real_cost != "0") |>
  type_convert() |>
  transmute(
    build_cost = real_cost / length,
    building_time_years = end_year - start_year,
    rail_lenght = length,
    how_many_stations = stations,
    tunnel_ratio = tunnel / rail_lenght,
    country = str_replace(country, "UK", "GB"),
    continent = countrycode::countrycode(country, "iso2c", "continent")
  )

transit_cost
```

```{r}
transit_cost |> skim()
```

## linearity & outliers

america seems to have outliers in the data


```{r}
library(colorspace)
hcl_palettes(type = "sequential")


plot_things <- function(.data, y_vals = length) {
  .data |>
    ggplot(aes(build_cost, {{ y_vals }}, color = continent)) +
    geom_jitter(alpha = 1 / 2) +
    geom_smooth(method = "lm", se = F) +
    labs(
      title = "Transit cost linearity per continent",
      subtitle = "build_cost, $building_time_years, $rail_lenght, $how_many_stations,$tunnel_ratio"
    ) +
    theme(legend.position = "bottom") +
    scale_color_discrete_sequential(palette = "Heat")
}



transit_cost |>
  select(!c("country", "continent")) |>
  map(\(x) plot_things(transit_cost, y_vals = x))
```

```{r}
transit_cost |>
  ggplot(aes(building_time_years, fill = continent)) +
  geom_bar() +
  labs(title = "Number of Trailway project and building time in different continents ")
```



## correlation

### complete dataset

tunnel ratio and building time have statistically significant correlation to build cost

```{r}
transit_cost |>
  correlation() |>
  summary()
```


### per continent

correlations diverge from full dataset results, when split to continents, outliers cause problems?

```{r}
library(correlation)

transit_cost |>
  group_by(continent) |>
  correlation() |>
  summary()
```
## continents imbalaced?

heavy focus on Asia and europe, imbalaced data, but the trend for these continents wasnt different

```{r}
transit_cost |>
  count(continent) |>
  mutate(ratio = scales::percent(n / sum(n)))
```
```{r}
transit_cost |>
  group_by(continent) |>
  summarise(across(where(is.double), list(mean = mean, median = median)))
```



# modeling

## split data

```{r}
library(tidymodels)
tidymodels_prefer()
```

split data to training and testing, i dont use validation set since the data size is small
testing set purpose is to confirm that the build model has potential to work with new data 

```{r}
set.seed(123)

initial_split <- initial_split(transit_cost)
initial_split
trn <- training(initial_split)
tst <- testing(initial_split)
```

## recipe

building tune and tunnel ratio seemed to have correlation with building cost. 
some of the tunnel ratios were missing, i use mean imputation to insert replacement data

```{r}
transit_rec <- recipe(build_cost ~ building_time_years + tunnel_ratio, data = trn) %>%
  step_impute_mean(tunnel_ratio) |>
  prep()
```

I am using standard 10 fold cross validation to test the models later, 


```{r}
transit_folds <- vfold_cv(trn, v = 10)
transit_folds
```

low bias (blackbox) models can learn the relationship so well that it memorizes the training set, which means that when model is used with test data, the performance can degrade. 

```{r}
models <- list(lin = linear_reg(), rand = rand_forest(mode = "regression"), xg = boost_tree(mode = "regression"))
modelset <- workflow_set(list(transit_rec), models)
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)
res <- modelset |> workflow_map("fit_resamples", seed = 10101, verbose = T, resamples = transit_folds, control = keep_pred)

res |> collect_metrics()
```

## xgbooost

```{r}
xgboost_model <- boost_tree(
  mode       = "regression",
  trees      = 1000,
  min_n      = tune(),
  tree_depth = tune(),
  learn_rate = tune()
) %>%
  set_engine("xgboost", objective = "reg:squarederror")

xgboost_model
```

```{r}
glmnet_params <- parameters(penalty(), mixture())
glmnet_params

set.seed(123)
glmnet_grid <- grid_max_entropy(glmnet_params, size = 20)
glmnet_grid
```



```{r}
glmnet_grid %>%
  ggplot(aes(penalty, mixture)) +
  geom_point(size = 3) +
  scale_x_log10() +
  labs(title = "Max Entropy Grid", x = "Penalty (log scale)", y = "Mixture")
```

```{r}
xgboost_params <- parameters(min_n(), tree_depth(), learn_rate())
xgboost_params

set.seed(123)
xgboost_grid <- grid_max_entropy(xgboost_params, size = 30)
xgboost_grid
```

```{r}
glmnet_stage_1_cv_results_tbl <- tune_grid(
  object = glmnet_model,
  preprocessor = transit_rec,
  resamples = car_cv_folds,
  grid = glmnet_grid,
  metrics = metric_set(mae, mape, rmse, rsq),
  control = control_grid(verbose = TRUE)
)
```



```{r}
xgboost_stage_1_cv_results_tbl <- tune_grid(
  object = xgboost_model,
  preprocessor = transit_rec,
  resamples = car_cv_folds,
  grid = xgboost_grid,
  metrics = metric_set(mae, mape, rmse, rsq),
  control = control_grid(verbose = TRUE)
)
```

TODO: select best model / conclusions


# vetiver control

```{r}
library(vetiver)
```
